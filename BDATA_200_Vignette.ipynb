{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e887bc2e",
   "metadata": {},
   "source": [
    "# Using Random Forest Regression and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645cc22",
   "metadata": {},
   "source": [
    "## About me\n",
    "\n",
    "My name is Gabriel Scott, and I am a senior majoring in Mathematics. Though I mostly study pure mathematics, I am very interested in operations research and transportation research. I first learned of these fields through my work in STMATH 381, Discrete Mathematical Modeling. To further my understanding of coding in python and real world modeling, I chose to expand on what was learned in 381 with real world travel data modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71742e",
   "metadata": {},
   "source": [
    "### Background\n",
    "Since part of my project is an analysis of how route predicts delay. It seems possible that a random forest regression could be constructed to predict Arrival Delay from the destination features. Destination is considered initially so the origin can be controlled. Rather than considering the whole network of routes, just routes departing a selected airport will be considered. This should provide less interaction and less noisy data for the Algorithm to Train and Test on.(Xu et al., 2008) The reach goal of this model is to be able to predict delay, but it would be useful to just know what features contribute to delay as well.\n",
    "\n",
    "Unfortunately, I was unable to create a model that is better than the baseline generated from getting the mean delay of the sample. However, this project still generates a modular way to find the destinations that yield the most affect on delay. This could lead to a meta-analysis of the geographic location of the airports to see if there is delay associated with location. Even a temporal analysis could be considered by including time features, as it has been found that time based trends affect air travel.(Tu et al., 2008).\n",
    "\n",
    "In this adaptation of the Random Forest exercise completed in class, the features and labels can be semi-modularly selected. Though the features and labels are hardcoded into some of the functions, it is very possible to change a couple lines to allow for more features or more labels given a certain originating airport. Additionally, the importance factors were ommitted as I could not reliably recreate this code without heavily copying the exercise project. In previous studies it was found that certain airports, due to climate or other factors, always have more delay,(Chatterji and Sridhar, 2005) and this could be validated if there were particular destinations that contribute more to arrival delay for various origins considered. I.e. We see a reporting destination occur high in the importance factors list for multiple origins.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2526f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "import pylab\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "\n",
    "data_path = \"airline_2m.csv\"\n",
    "\n",
    "#CSV Can be directly downloaded as a tar file here: \n",
    "\n",
    "#https://dax-cdn.cdn.appdomain.cloud/dax-airline/1.0.1/airline_2m.tar.gz?_ga=2.241493383.460169643.1645306071-17791737.1643504108\n",
    "\n",
    "# Credit to IBM's Airline Dataset for the data and encoding code.\n",
    "\n",
    "\n",
    "data = pd.read_csv(data_path, encoding = \"ISO-8859-1\",\n",
    "                 dtype={'Div1Airport': str, 'Div1TailNum': str, 'Div2Airport': str, 'Div2TailNum': str})\n",
    "#Code Provided By IBMs Airline Reporting Carrier on-time performance set. \n",
    "#This helps python better interpret the data frame because it is not encoded in UTF-8 \n",
    "#An alternative to this could be to actually change the file to be encoded in UTF-8\n",
    "#but this was difficult to do with how big the file was."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539929d",
   "metadata": {},
   "source": [
    "### originSampler\n",
    "This function samples the data and automatically restricts the frame to the data for the flights regarding the airport we want. A sample is also generated in the cell below for ease of example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f239b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data.sample(10000, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c24e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def originSampler(df, orig):\n",
    "    \"\"\"\n",
    "    origin(Dataframe, Origin Airport IATA code)\n",
    "    Changes the dataframe to only include flights\n",
    "    from the origin code.\n",
    "    Example:\n",
    "    orginSampler(sample,'SEA') \n",
    "    sample = dataframe, orig = 'SEA'\n",
    "    \"\"\"\n",
    "    originSubset = df[df['Origin'] == orig]\n",
    "    return originSubset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c45f2e",
   "metadata": {},
   "source": [
    "### oneHot\n",
    "This function one hot encodes the dataset and returns the labels and features. The arrival delay has NaN values for no delay, this is rectified by adding 0s in. Furthermore, it drops the rest of the rows that have remaining NaN values. Notice that the only features considered are destination and delay. Origin is already accounted for by originSampler, and more features can be considered by modifying the column names of the df call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ce1dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot(df):\n",
    "    \"\"\"\n",
    "    This function takes in a dataframe and onehot\n",
    "    encodes it with the label set to be the Arrival Delay\n",
    "    and the Feature set to be Destination.\n",
    "    It returns the labels and features\n",
    "    \n",
    "    \"\"\"\n",
    "    #Selecting only the wanted features from the sample\n",
    "    df = df[['Dest','ArrDelay']]\n",
    "    #Filling the NaN entries with 0, this is standard for the Dataset, as NaN represents\n",
    "    #no delay for the sake of this particular dataset.\n",
    "    df['ArrDelay'].fillna(0)\n",
    "    sample_OH = df.dropna(axis = 0)\n",
    "    #Print-check of the selected features.\n",
    "    print(df.columns)\n",
    "    #The actual hot-encoding step, adds the encoding for the\n",
    "    #categorical data in the sample.\n",
    "    print(df.head())\n",
    "    \n",
    "    features = pd.get_dummies(sample_OH)\n",
    "    #Print-check for successful one-hot encoding.\n",
    "    print(features.head())\n",
    "\n",
    "    # The chosen label is ArrDelay. i.e. We are Predicting Arrival Delay\n",
    "    labels = np.array(features['ArrDelay'])\n",
    "    # Remove labels from the features\n",
    "    features = features.drop('ArrDelay', axis = 1)\n",
    "    # Convert to numpy array\n",
    "    features = np.array(features)\n",
    "    #return the labels and features\n",
    "    return labels, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3da44d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Dest', 'ArrDelay'], dtype='object')\n",
      "        Dest  ArrDelay\n",
      "458182   ORD       6.0\n",
      "1108738  SAN      -6.0\n",
      "383793   SJC      -2.0\n",
      "633893   LAX     -14.0\n",
      "1422016  ORD      -9.0\n",
      "         ArrDelay  Dest_ANC  Dest_ATL  Dest_AUS  Dest_BNA  Dest_BOI  Dest_BOS  \\\n",
      "458182        6.0         0         0         0         0         0         0   \n",
      "1108738      -6.0         0         0         0         0         0         0   \n",
      "383793       -2.0         0         0         0         0         0         0   \n",
      "633893      -14.0         0         0         0         0         0         0   \n",
      "1422016      -9.0         0         0         0         0         0         0   \n",
      "\n",
      "         Dest_BUR  Dest_BWI  Dest_CLE  ...  Dest_RDU  Dest_SAN  Dest_SBA  \\\n",
      "458182          0         0         0  ...         0         0         0   \n",
      "1108738         0         0         0  ...         0         1         0   \n",
      "383793          0         0         0  ...         0         0         0   \n",
      "633893          0         0         0  ...         0         0         0   \n",
      "1422016         0         0         0  ...         0         0         0   \n",
      "\n",
      "         Dest_SFO  Dest_SJC  Dest_SLC  Dest_SMF  Dest_SNA  Dest_STL  Dest_TPA  \n",
      "458182          0         0         0         0         0         0         0  \n",
      "1108738         0         0         0         0         0         0         0  \n",
      "383793          0         1         0         0         0         0         0  \n",
      "633893          0         0         0         0         0         0         0  \n",
      "1422016         0         0         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "#Example Call\n",
    "labels, features = oneHot(originSampler(sample, 'SEA'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d365dc",
   "metadata": {},
   "source": [
    "### Train and Split\n",
    "\n",
    "This is the same code used in the exercise. I was going to change the nomenclature used, but it became difficult to keep track of these variable names and the dummy parameter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6667e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# This was taken from the Random Forest Exercise\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1035ffe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ab9ee",
   "metadata": {},
   "source": [
    "### baseLine \n",
    "This function takes in the split up training features and test features to create an array that is populated by the average delay that is the length of the test features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21acad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseLine(trainFeatures, testFeatures):\n",
    "    \"\"\"\n",
    "    This function takes in the trained features and tested features\n",
    "    and makes a list of the mean of the trained features that\n",
    "    is the length of the test features\n",
    "    \n",
    "    \"\"\"\n",
    "    #go down the train features row by row and pullout delay values \n",
    "    #This line is from an article I found on creating\n",
    "    #Zero Algorithm for classification.\n",
    "    #https://machinelearningmastery.com/implement-baseline-machine-learning-algorithms-scratch-python/\n",
    "    values = [row[-1] for row in trainFeatures]\n",
    "    #Calculates the mean delay value\n",
    "    mean = sum(values) / float(len(values))\n",
    "    #Populate a list called predicted that is the length of the test features\n",
    "    predicted = [mean for i in range(len(testFeatures))]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d280dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the RF regressor\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 420)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "# Use the forest's predict method on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8906900",
   "metadata": {},
   "source": [
    "### baselineChecker\n",
    "This function generates baseline_errors from baseLine and prints them out to be compared with predictCheck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f82ba8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineChecker(baseLine):\n",
    "    # The baseline predictions were generated in baseLine()\n",
    "    baseline_pred = np.array(baseLine)\n",
    "    # Baseline errors, and display average baseline error\n",
    "    baseline_errors = abs(baseline_pred - test_labels)\n",
    "    print('Average baseline error: ', np.mean(baseline_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "94fef767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  18.118815738215815\n"
     ]
    }
   ],
   "source": [
    "#Example Call\n",
    "baselineChecker(baseLine(train_features, test_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c67f38",
   "metadata": {},
   "source": [
    "### predictCheck\n",
    "This function generates the errors of the predictions that the model generated. Notice that the error is greater than the baseline error. This signifies that the model does a worse job than average, and this model needs to include more or be paramterized in some manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04304e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCheck(testFeatures, testLabels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_features)\n",
    "    # Calculate the absolute errors\n",
    "    errors = abs(predictions - test_labels)\n",
    "    # Print out the mean absolute error (mae)\n",
    "    print('Mean Absolute Error:', np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b547df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 22.41106941529259\n"
     ]
    }
   ],
   "source": [
    "#Example Call\n",
    "predictCheck(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d434458",
   "metadata": {},
   "source": [
    "## Further Readings and Citations\n",
    "\n",
    "\n",
    "- Zero Rule Algorithm Regression Reading:\n",
    " https://machinelearningmastery.com/implement-baseline-machine-learning-algorithms-scratch-python/\n",
    " \n",
    "- Enhanced Random Forest Methods:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Citations\n",
    "\n",
    "Chatterji, G., Sridhar, B., 2005. National Airspace System Delay Estimation Using Weather \n",
    "Weighted Traffic Counts, in: AIAA Guidance, Navigation, and Control Conference and \n",
    "Exhibit. Presented at the AIAA Guidance, Navigation, and Control Conference and \n",
    "Exhibit, American Institute of Aeronautics and Astronautics, San Francisco, California. \n",
    "https://doi.org/10.2514/6.2005-6278\n",
    "\n",
    "Tu, Y., Ball, M.O., Jank, W.S., 2008. Estimating Flight Departure Delay Distributions—A \n",
    "Statistical Approach With Long-Term Trend and Short-Term Pattern. J. Am. Stat. Assoc. \n",
    "103, 112–125. https://doi.org/10.1198/016214507000000257\n",
    "\n",
    "Xu, N., Sherry, L., Laskey, K.B., 2008. Multifactor Model for Predicting Delays at U.S. \n",
    "Airports. Transp. Res. Rec. 2052, 62–71. https://doi.org/10.3141/2052-08\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
